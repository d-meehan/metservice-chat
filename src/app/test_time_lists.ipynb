{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "import instructor\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\"THE CURRENT DATE AND TIME IS {current_datetime}.\\n\"\n",
    "                 \"THE USER'S LOCATION IS {user_location}\\n\"\n",
    "                 \"You are WeatherBot, a chatbot that can answer any user query about the weather.\\n\"\n",
    "                 \"You will receive a user query and must respond with the outlined JSON structure.\\n\"\n",
    "                 \"When answering, please adhere to the following rules:\\n\"\n",
    "                 \"- If the query is not weather related, answer the user query as best as you can and remind them that you are a weather bot. \\n\"\n",
    "                 \"- If the query is about the weather and the data available to you is sufficient to provide an answer, answer the user query as WeatherBot. Open your query with a succint summary of the weather and give the most important details.\\n\"\n",
    "                 \"- Only answer weather queries based on the information you receive from a weather API, found in the DATA STORE. \\n\"\n",
    "                 \"- If the data is insufficient to answer the query or there is no data, you can request data from the API by returning sufficient_data_check as False and requesting additional data using the other fields. \\n\"\n",
    "                 \"- We need to limit how many API calls we make, so only request data if it's really necessary. Try and work with what is in the data store if possible. \\n\"\n",
    "                 \"- If the data is insufficient, include a holding message in the response field while we request data from the API. \\n\"\n",
    "                 \"- If you need to make an API request please ensure that it will provide the right data for another language model to answer the query. For example if the request is for the weather tomorrow, you will need data at hourly intervals to give a complete answer. \\n\"\n",
    "                 \"- For variables, you can select from the provided list. Please only select the most relevant variables to answer the query. \\n\"\n",
    "                 \"- If a location is not specified in the query, return location as empty. \\n\"\n",
    "                 \"- If the request doesn't contain a specific time, make sure that the times field will request enough data from the API for a language model to answer the query with the received data.\\n\"\n",
    "                 \"- Times can only be values on the hour, e.g. 2022-01-01T00:00:00Z, 2022-01-01T01:00:00Z, 2022-01-01T02:00:00Z, etc.\\n\"\n",
    "                 \"- If the user request is for the weather now, please request the data at the previous hour mark plus one additional hour of data.\\n\"\n",
    "                 \"- If you are able to answer the weather query and don't need to request more data, explain what data you used from the data store by specifying the variables you used in the variables field, the location you used in the location field and the times you used in the times field. \\n\"\n",
    "                 \"- Don't go into too much detail, be succinct. No one likes to hear every single detail about the weather.\\n\\n\"\n",
    "\n",
    "                 \"______________________________\\n\"\n",
    "                 \"DATA STORE\\n\"\n",
    "                 \"______________________________\\n\"\n",
    "                 \"{data_store}\\n\"\n",
    "                 \"______________________________\\n\"\n",
    "                 \"VARIABLES\"\n",
    "                 \"______________________________\\n\"\n",
    "                 \"{vars}\\n\"\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "METSERVICE_VARIABLES = [\n",
    "    'air.humidity.at-2m',\n",
    "    'air.pressure.at-sea-level',\n",
    "    'air.temperature.at-2m',\n",
    "    'air.visibility',\n",
    "    'atmosphere.convective.potential.energy',\n",
    "    'cloud.base.height',\n",
    "    'cloud.cover',\n",
    "    'precipitation.rate',\n",
    "    'radiation.flux.downward.longwave',\n",
    "    'radiation.flux.downward.shortwave',\n",
    "    'wind.direction.at-10m',\n",
    "    'wind.direction.at-100m',\n",
    "    'wind.speed.at-10m',\n",
    "    'wind.speed.at-100m',\n",
    "    'wind.speed.eastward.at-100m',\n",
    "    'wind.speed.eastward.at-10m',\n",
    "    'wind.speed.gust.at-10m',\n",
    "    'wind.speed.northward.at-100m',\n",
    "    'wind.speed.northward.at-10m',\n",
    "    'wave.height',\n",
    "    'wave.height.max',\n",
    "    'wave.direction.peak',\n",
    "    'wave.period.peak',\n",
    "    'wave.height.above-8s',\n",
    "    'wave.height.below-8s',\n",
    "    'wave.period.above-8s.peak',\n",
    "    'wave.period.below-8s.peak',\n",
    "    'wave.direction.above-8s.peak',\n",
    "    'wave.direction.below-8s.peak',\n",
    "    'wave.direction.mean',\n",
    "    'wave.directional-spread',\n",
    "    'wave.period.tm01.mean',\n",
    "    'wave.period.tm02.mean',\n",
    "    'current.speed.eastward.at-sea-surface',\n",
    "    'current.speed.eastward.at-sea-surface-no-tide',\n",
    "    'current.speed.eastward.barotropic',\n",
    "    'current.speed.eastward.barotropic-no-tide',\n",
    "    'current.speed.northward.at-sea-surface',\n",
    "    'current.speed.northward.at-sea-surface-no-tide',\n",
    "    'current.speed.northward.barotropic',\n",
    "    'current.speed.northward.barotropic-no-tide',\n",
    "    'sea.temperature.at-surface',\n",
    "    'sea.temperature.at-surface-anomaly',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResponseToWeatherQuery(BaseModel):\n",
    "    \"\"\"Request model for weather queries.\"\"\"\n",
    "    response: str = Field(..., title='Response',\n",
    "                          description='Response from WeatherBot to the user query')\n",
    "    weather_query_check: bool = Field(..., title='Weather query check',\n",
    "                                      description='Is the user message a weather query?')\n",
    "    sufficient_data_check: bool = Field(..., title='Sufficient data check',\n",
    "                                        description='Does the data_store contain sufficient data to answer the query?')\n",
    "    data_check_rationale: str = Field(..., title='Data check rationale',\n",
    "                                      description='Reason for the result you have given for the sufficient_data_check')\n",
    "    location: str\n",
    "    variables: List[str]\n",
    "    start_time: datetime = Field(..., title='Start Time',\n",
    "                               description='The first time to request data for, formatted as :%Y-%m-%dT00:00:00Z')\n",
    "    end_time: datetime = Field(..., title='End Time',\n",
    "                                description='The last time to request data for, formatted as :%Y-%m-%dT00:00:00Z')\n",
    "    interval: Literal['hour','day'] = Field(..., title='Time interval', description='Time interval for the data.')\n",
    "                                            \n",
    "    \n",
    "    # interval: Optional[str] = Field(\n",
    "    #     None, title='Time interval', description='Time interval for the data. \\\n",
    "    #         For example, \"1h\" for hourly data, \"3h\" for 3 hour intervals etc.')\n",
    "    # repeat: Optional[int] = Field(None, title='Number of intervals',\n",
    "    #                               description='Number of instances to request the data for. \\\n",
    "    #         For example, if interval is \"1h\", \"3\" will request 3 hours of data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0s/pn0r0b8120ngcq1d6j4d6tzc0000gn/T/ipykernel_52712/1991695110.py:1: DeprecationWarning: apatch is deprecated, use patch instead\n",
      "  pydantic_client = instructor.apatch(\n"
     ]
    }
   ],
   "source": [
    "pydantic_client = instructor.apatch(\n",
    "    openai.OpenAI(api_key=os.environ['OPENAI_API_KEY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT response: response='Holding message while data is being fetched.' weather_query_check=True sufficient_data_check=False data_check_rationale='Insufficient data available to provide a direct answer.' location='Auckland' variables=[] start_time=datetime.datetime(2024, 2, 19, 0, 0, tzinfo=TzInfo(UTC)) end_time=datetime.datetime(2024, 2, 20, 0, 0, tzinfo=TzInfo(UTC)) interval='day'\n"
     ]
    }
   ],
   "source": [
    "formatted_data = \"No data has been requested yet.\"\n",
    "\n",
    "system_prompt = SYSTEM_PROMPT.format(\n",
    "    current_datetime=datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    user_location=\"unknown\",\n",
    "    data_store=formatted_data,\n",
    "    vars=METSERVICE_VARIABLES\n",
    ")\n",
    "\n",
    "messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What is the weather like in Auckland tomorrow?\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response_model=ModelResponseToWeatherQuery\n",
    "\n",
    "response = pydantic_client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\",\n",
    "    response_model=response_model,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "assert isinstance(response, ModelResponseToWeatherQuery)\n",
    "print(f\"GPT response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
